id: injector_inria_ml_v1
title: "INRIA — Machine Learning Robustness Injector"
version: "1.0.0"
metadata:
  purpose: "Audit ML reproducibility with adversarial tests and compliance"
  lab: INRIA
  domain: machine_learning
pipeline:
  - capability: core.loader
    params: { path: "workspace/ml", entry_point: "train_model.py" }
  - capability: glyphnet.instrumentation
    params: { mode: "python_augmented", glyphs: ["⟦CORE:ΔM11.3⟧","⟦Audit:ML⟧","⟦Ethic:Chain⟧"] }
  - capability: tests.adversarial
    params: { attacks: ["fgsm","pgd"] }
  - capability: tests.property_based
    params: { module: "tests/test_ml.py" }
  - capability: tests.mutation
    params: { threshold: 80 }
  - capability: governance.trust_report
    params: { sign_with: "KeyGuardian", output_formats: ["json","pdf","latex"] }
outputs:
  - name: trust_report
    path: "./outputs/inria_ml_trust_v1.json"
